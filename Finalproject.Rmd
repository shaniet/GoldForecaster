---
title: "Final Project"
author: "Shanie Talor, Arif Abd Aziz, Jon Girolamo"
date: '2023-06-02'
output: pdf_document
---

# Introduction

(We don't have to polish this RMD in terms of labels or descriptions. Final presentation will be in powerpoint. We'll still submit this as the source code though so we should still be commenting what we're doing with code) Jon

# Load Data
```{r}
# Read csv
gold <- read.csv("gold.csv", sep = ",", header = TRUE)

# Omit all rows that have NA Values: 6 Rows: 05/31/1979 to 03/31/2023
gold <- na.omit(gold)

# Add Binary Classifier Variable
gold$Binary.PercChange <- ifelse(gold$PercChangeForc > 0.1, 1, 0) 

# Check if Features Are Numeric (Returns False, So Non-Numeric Variables)
all(sapply(gold, is.numeric))


gold <- gold[,-26]
gold <- gold[,-24]
gold <- gold[,-2]
gold <- gold[,-1]

head(gold)
# Head Gold
head(gold)
```

We converted our percent change forecast variable into a binary classifier. The hurdle rate for our binary classifier ("Binary.PercChange") is set at 0.1%, so that edge cases that are very close to 0% (0%:0.0999%) are classified as non-investment opportunities. Percent changes in gold (month over month) greater than 0.1% will be considered "buy" opportunities, with a classifier value of 1. 

# Initial Analysis of Features 

In order to better understand our features, we'll first look at the histograms of our features as well as the scatterplots between our features and our main response variables: monthly percent changes in gold for our regression problem and our binary classiifer for our classification problem. 

### Histogram for Loops
```{r}
# Set Feature Space Excluding Lagged Variables and Other Miscellenous Feature 
library(dplyr)
library(ggplot2)
library(stats)
library(reshape2)
gold_histograms <- gold %>% select(-c("Date","PercChangeLag1","PercChangeLag2",
                                "PercChangeLag3", "PercChangeLag4",
                                "PercChangeLag5","Inf.L1","Inf.L2",
                                "Inf.L3","Inf.L4","FedFundsRateL1"))
gold_histograms <- as.data.frame(lapply(gold_histograms, as.numeric))
head(gold_histograms)

# For Loop for Histograms
for (feature in names(gold_histograms)){
  hist(gold_histograms[[feature]], xlab = paste0(feature), ylab = "Frequency",
       main = paste0("Histogram of ",feature))
}

# For Loop for Box Plots
for (feature in names(gold_histograms)){
  boxplot(gold_histograms[[feature]], ylab = paste0("Value of ",feature),
       main = paste0("Boxplot of ",feature))
}
```

The boxplots and histograms show that our variables are on average normally distributed. There are outliers in some of our features, such as percent changes in monthly prices and changes in bank reserves. However, we believe these outliers are still essential in predicting the movement of gold prices. 

### Correlation Values
```{r} 
# Data Clean for Scatter Plots 
set.seed(490782)
gold_cor <- gold %>% select(-c("Date","Average.Price")) 
gold_cor <- as.data.frame(lapply(gold_cor, as.numeric))
head(gold_cor)

# For Loop for Scatter Plots 
for (feature in names(gold_cor)[!names(gold_cor) %in% c("Binary.PercChange")]){
  plot(gold_cor[[feature]], gold_cor$PercChangeForc, type = "p",
       xlab = paste(feature), ylab = "Monthly Forecasted Change in Gold Prices",
       main = paste0("Monthly Changes in Gold Prices Against ",feature)) 
  line <- lm(gold_cor$PercChangeForc ~ gold_cor[[feature]])
  abline(line, col = "blue")
}

# Heat Map
cor_matrix <- round(cor(gold_cor),2)
melted_cor_gold <- melt(cor_matrix)
ggplot(data = melted_cor_gold, aes(x = Var1, y = Var2, fill = value))+
  geom_tile()
```

# Initial Data Cleaning
```{r}

```

# Feature Selection
```{r}
# Run Boruta  algorithm on clean data
library(Boruta)
library(randomForest)
boruta.gold <- Boruta(PercChangeForc~. -Binary.PercChange, data = gold, doTrace = 2, 
                       randomForest = TRUE)

plot(boruta.gold)

```

Create Cross Validation Folds (Regression)

```{r}
library(caret)
set.seed(123)
folds <- createFolds(gold$PercChangeForc, k = 5, returnTrain = TRUE)
```

# Regression

### OLS
```{r}
<<<<<<< HEAD
lin.reg <- lm(PercChangeForc~., data = gold_histograms)
=======
# Run linear regression
lin.reg <- lm(PercChangeForc~.-Binary.PercChange, data = gold)
>>>>>>> 1bc783392c7d0973c5472cdcd1ce6416f319662c
summary(lin.reg)



```

### Random Forest + Bagging
```{r}

```

### Boosting
```{r}

```


### Neural Network
```{r}

```


--------------------------------------------------------------------------------

# Classification

### Support Vector Machine
```{r}

```

### Neural Network
```{r}

```









